{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/db/7c/9a60add21b96140e22465d9adf09832feade45235cd22f4cb1668a25e443/pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/kurichannn/.pyenv/versions/3.12.0/envs/openai-env/lib/python3.12/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kurichannn/.pyenv/versions/3.12.0/envs/openai-env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kurichannn/.pyenv/versions/3.12.0/envs/openai-env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_templates(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "templates_df = load_templates('templates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings from OpenAI\n",
    "def get_embeddings(text_list, model=\"text-embedding-ada-002\"):\n",
    "    response = client.embeddings.create(model=model, input=text_list)\n",
    "    #print(response.data[0])\n",
    "    return [item.embedding for item in response.data]\n",
    "    #return res\n",
    "\n",
    "# Convert templates to text format for embedding\n",
    "template_texts = templates_df['description'].tolist()\n",
    "template_metadata = templates_df[['type', 'role']].values.tolist()\n",
    "\n",
    "# Get embeddings for the templates\n",
    "template_embeddings = get_embeddings(template_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings and metadata saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings and metadata to a file\n",
    "with open('template_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump((template_embeddings, template_metadata), f)\n",
    "\n",
    "print(\"Embeddings and metadata saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings and metadata from file\n",
    "with open('template_embeddings.pkl', 'rb') as f:\n",
    "    template_embeddings, template_metadata = pickle.load(f)\n",
    "\n",
    "# Normalize embeddings\n",
    "def normalize_embeddings(embeddings):\n",
    "    norms = np.linalg.norm(embeddings, axis=0, keepdims=True)\n",
    "    return embeddings / norms\n",
    "\n",
    "# Normalize the template embeddings\n",
    "template_embeddings = normalize_embeddings(np.array(template_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the most similar template\n",
    "def find_best_template(types_roles):\n",
    "    query_text = \" \".join([f\"This is a {tr['type']} layout for {tr['role']}.\" for tr in types_roles])\n",
    "    query_embedding = get_embeddings([query_text])[0]\n",
    "    \n",
    "    # Normalize the query embedding\n",
    "    query_embedding_np = np.array(query_embedding)\n",
    "    query_embedding_np = query_embedding_np / np.linalg.norm(query_embedding_np)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    dot_product = np.dot(template_embeddings, query_embedding_np)\n",
    "    best_match_index = np.argmax(dot_product)\n",
    "    \n",
    "    best_template_metadata = template_metadata[best_match_index]\n",
    "    best_template = templates_df[\n",
    "        (templates_df['type'] == best_template_metadata[0]) &\n",
    "        (templates_df['role'] == best_template_metadata[1])\n",
    "    ]['description'].values[0]\n",
    "    \n",
    "    return best_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_template_with_openai(template, customer_name, types_roles):\n",
    "    prompt = f\"\"\"\n",
    "    Create a layout for a Customer 360 view for {customer_name} based on the following details:\n",
    "    {template}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    system_message = f\"\"\"\n",
    "    You are HOLO, a highly advanced AI designed to dynamically generate and enhance UI layouts for a bank.\n",
    "    Your goal is to create the most efficient and user-friendly Customer 360 views based on provided details.\n",
    "    You need to reply in a json format with these properties\"\n",
    "    topSection:\n",
    "      customerInfo:\n",
    "        components: this is an array of the components used for customerInfo\n",
    "    mainContentArea:\n",
    "      layout: one-column or two-column\n",
    "      sections: this is array of the components displayed in the main contennt area\n",
    "\n",
    "    For example:\n",
    "    {{\n",
    "      \"topSection\": {{\n",
    "        \"customerInfo\": {{\n",
    "          \"components\": [\"name\", \"email\", \"phone\"]\n",
    "        }}\n",
    "      }},\n",
    "      \"mainContentArea\": {{\n",
    "        \"layout\": \"two-column\",\n",
    "        \"sections\": [\"accounts\", \"transactions\", \"loans\"]\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=250,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    print(\"holo response is \", response.choices[0].message.content)\n",
    "    enhanced_layout = response.choices[0].message.content\n",
    "    return json.loads(enhanced_layout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Bank manager layout. Top section includes: Name, Status, ID, Last Interaction. Main content area (two-column): Account Overview, Team Performance, High Value Transactions, Quick Links.\"\n",
      "holo response is  {\n",
      "  \"topSection\": {\n",
      "    \"customerInfo\": {\n",
      "      \"components\": [\"name\", \"status\", \"id\", \"lastInteraction\"]\n",
      "    }\n",
      "  },\n",
      "  \"mainContentArea\": {\n",
      "    \"layout\": \"two-column\",\n",
      "    \"sections\": [\"accountOverview\", \"teamPerformance\", \"highValueTransactions\", \"quickLinks\"]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "types_roles_test = [\n",
    "    {\"type\": \"customer\", \"role\": \"VIP\"},\n",
    "    {\"type\": \"bank\", \"role\": \"bank manager\"},\n",
    "    {\"type\": \"screen\", \"role\": \"ipad\"}\n",
    "]\n",
    "\n",
    "# Call the function and print the result\n",
    "best_template_result = find_best_template(types_roles_test)\n",
    "print(json.dumps(best_template_result, indent=4))\n",
    "enhanced_template_result = enhance_template_with_openai(best_template_result, \"Naomi Payton\", types_roles_test)\n",
    "#print(enhanced_template_result, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities: [ 0.00715392 -0.04976986 -0.00179182 ... -0.01311106  0.0054557\n",
      "  0.03976775]\n"
     ]
    }
   ],
   "source": [
    "# Print similarities for debugging\n",
    "def print_similarities(types_roles):\n",
    "    query_text = json.dumps(types_roles)\n",
    "    query_embedding = get_embeddings([query_text])[0]\n",
    "    \n",
    "    query_embedding_np = np.array(query_embedding)\n",
    "    query_embedding_np = query_embedding_np / np.linalg.norm(query_embedding_np)\n",
    "    \n",
    "    dot_product = np.dot(template_embeddings, query_embedding_np)\n",
    "    \n",
    "    print(\"Similarities:\", dot_product)\n",
    "\n",
    "print_similarities(types_roles_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
